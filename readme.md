# Big Data Assignment 1

A collection of Hadoop MapReduce and PySpark programs for text processing, metadata analysis, and similarity computation on large datasets including Project Gutenberg texts.

## Repository Structure

### Hadoop MapReduce Word Count

| File | Description |
|------|-------------|
| `WordCount.java` | An enhanced MapReduce word count program for Hadoop. It tokenizes input text, removes punctuation, converts words to lowercase, and counts occurrences. Supports configurable HDFS split sizes (`mapreduce.input.fileinputformat.split.maxsize` and `split.minsize`) for performance tuning. |
| `WordCountOriginal.java` | The original, simpler version of the word count MapReduce job. Performs basic tokenization and word counting without punctuation removal or split size configuration. |
| `auto_run_script.sh` | A bash automation script that runs the `WordCount` job across varying HDFS split sizes (512 KB to 64 MB). It records the number of mappers launched and execution time for each configuration, appending results to a log file. |

### PySpark Analytics

| File | Description |
|------|-------------|
| `metadata_analysis.py` | A PySpark program that extracts and analyzes metadata from Project Gutenberg book files. It parses fields such as title, release date, language, and character encoding, then computes aggregate statistics including books published per year, the dominant language, and average title length. |
| `author_influence.py` | A PySpark program that builds an author-influence network from Project Gutenberg texts. Authors published within 5 years of each other are connected in a directed graph, and the script identifies the most influential (highest out-degree) and most influenced (highest in-degree) authors. |
| `tfidf_similarity.py` | A PySpark ML pipeline that computes TF-IDF vectors for Project Gutenberg texts and calculates cosine similarity between them to find the 5 most similar books to the King James Bible. |

### Input / Output Files

| File | Description |
|------|-------------|
| `file01` | Sample input file containing `Hello World Bye World`. |
| `file02` | Sample input file containing `Hello Hadoop Goodbye Hadoop`. |
| `lyrics.txt` | Sample text file with song lyrics, used as additional test input. |
| `output.txt` | Word count output generated by the MapReduce job. |
| `results_final.txt` | Performance results table showing split size, number of mappers, and execution time (ms) for each `auto_run_script.sh` run. |
